{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize,sent_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, NuSVC,SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score,precision_score,recall_score, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data and define the columns\n",
    "df1 = pd.read_csv('./data-1_train.csv')\n",
    "df1.columns = ['example_id', 'text', 'aspect_term', 'term_location', 'class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing n gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176577394462097"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df1.copy()\n",
    "data2 = data.copy()\n",
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.7, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= 'word', ngram_range=(1,5),lowercase=True)\n",
    "X = vec.fit_transform(data['text'])\n",
    "svm = LinearSVC(C=1.2)\n",
    "pred_weights = cross_val_predict(svm,X,data['class'],cv = 10)\n",
    "np.mean(pred_weights == data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3246"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intitalize count vectorizer\n",
    "countVectorizer = CountVectorizer()\n",
    "#get the list of vocab\n",
    "count_matrix = countVectorizer.fit_transform(df1['text'])\n",
    "vocab = list(countVectorizer.vocabulary_.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2333_1</td>\n",
       "      <td>Obviously one of the most important features o...</td>\n",
       "      <td>human interface</td>\n",
       "      <td>69--84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1805_1</td>\n",
       "      <td>Good for every day computing and web browsing.</td>\n",
       "      <td>every day computing</td>\n",
       "      <td>9--28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2782_2</td>\n",
       "      <td>while the keyboard itself is alright[comma] th...</td>\n",
       "      <td>mouse command buttons</td>\n",
       "      <td>115--136</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1385_0</td>\n",
       "      <td>Again[comma] the same problem[comma] the right...</td>\n",
       "      <td>right speaker</td>\n",
       "      <td>29--42</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1423_0</td>\n",
       "      <td>My problem was with DELL Customer Service.</td>\n",
       "      <td>DELL Customer Service</td>\n",
       "      <td>20--41</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text  \\\n",
       "0     2333_1  Obviously one of the most important features o...   \n",
       "1     1805_1     Good for every day computing and web browsing.   \n",
       "2     2782_2  while the keyboard itself is alright[comma] th...   \n",
       "3     1385_0  Again[comma] the same problem[comma] the right...   \n",
       "4     1423_0         My problem was with DELL Customer Service.   \n",
       "\n",
       "             aspect_term term_location  class  \n",
       "0        human interface        69--84      0  \n",
       "1    every day computing         9--28      1  \n",
       "2  mouse command buttons      115--136     -1  \n",
       "3          right speaker        29--42     -1  \n",
       "4  DELL Customer Service        20--41     -1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(data):\n",
    "    #replace [comma] with a ','\n",
    "    data = data.replace(\"[comma]\",\",\")\n",
    "    \n",
    "    #tokenize with punctuations\n",
    "    data = \" \".join(wordpunct_tokenize(data))\n",
    "    \n",
    "    #remove punctuations\n",
    "    nopunc = [char for char in data if char not in string.punctuation]\n",
    "    \n",
    "    #join the words and remove stopswords\n",
    "    data = \"\".join(nopunc)\n",
    "    data = [text for text in data.strip().split() if text not in set(stopwords.words('english'))]  \n",
    "    #message = [snowball.stem(w) for w in message]\n",
    "    \n",
    "    #convert the text into word tokens\n",
    "    data = \" \".join(data)\n",
    "    words = word_tokenize(data)\n",
    "    \n",
    "    #lemmatize using wordNetLemmatizer\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    #return processed data\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process text and aspect term columns of input data\n",
    "df1['clean_text'] = df1['text'].apply(processData)\n",
    "df1['clean_aspect_term'] = df1['aspect_term'].apply(processData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_aspect_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2333_1</td>\n",
       "      <td>Obviously one of the most important features o...</td>\n",
       "      <td>human interface</td>\n",
       "      <td>69--84</td>\n",
       "      <td>0</td>\n",
       "      <td>[Obviously, one, important, feature, computer,...</td>\n",
       "      <td>[human, interface]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1805_1</td>\n",
       "      <td>Good for every day computing and web browsing.</td>\n",
       "      <td>every day computing</td>\n",
       "      <td>9--28</td>\n",
       "      <td>1</td>\n",
       "      <td>[Good, every, day, computing, web, browsing]</td>\n",
       "      <td>[every, day, computing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2782_2</td>\n",
       "      <td>while the keyboard itself is alright[comma] th...</td>\n",
       "      <td>mouse command buttons</td>\n",
       "      <td>115--136</td>\n",
       "      <td>-1</td>\n",
       "      <td>[keyboard, alright, plate, around, cheap, plas...</td>\n",
       "      <td>[mouse, command, button]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1385_0</td>\n",
       "      <td>Again[comma] the same problem[comma] the right...</td>\n",
       "      <td>right speaker</td>\n",
       "      <td>29--42</td>\n",
       "      <td>-1</td>\n",
       "      <td>[Again, problem, right, speaker, work]</td>\n",
       "      <td>[right, speaker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1423_0</td>\n",
       "      <td>My problem was with DELL Customer Service.</td>\n",
       "      <td>DELL Customer Service</td>\n",
       "      <td>20--41</td>\n",
       "      <td>-1</td>\n",
       "      <td>[My, problem, DELL, Customer, Service]</td>\n",
       "      <td>[DELL, Customer, Service]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text  \\\n",
       "0     2333_1  Obviously one of the most important features o...   \n",
       "1     1805_1     Good for every day computing and web browsing.   \n",
       "2     2782_2  while the keyboard itself is alright[comma] th...   \n",
       "3     1385_0  Again[comma] the same problem[comma] the right...   \n",
       "4     1423_0         My problem was with DELL Customer Service.   \n",
       "\n",
       "             aspect_term term_location  class  \\\n",
       "0        human interface        69--84      0   \n",
       "1    every day computing         9--28      1   \n",
       "2  mouse command buttons      115--136     -1   \n",
       "3          right speaker        29--42     -1   \n",
       "4  DELL Customer Service        20--41     -1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  [Obviously, one, important, feature, computer,...   \n",
       "1       [Good, every, day, computing, web, browsing]   \n",
       "2  [keyboard, alright, plate, around, cheap, plas...   \n",
       "3             [Again, problem, right, speaker, work]   \n",
       "4             [My, problem, DELL, Customer, Service]   \n",
       "\n",
       "           clean_aspect_term  \n",
       "0         [human, interface]  \n",
       "1    [every, day, computing]  \n",
       "2   [mouse, command, button]  \n",
       "3           [right, speaker]  \n",
       "4  [DELL, Customer, Service]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to assign weights\n",
    "def assign_weights(data):\n",
    "    \n",
    "    #get the te\n",
    "    text = data[0]\n",
    "    aspect =data[1]\n",
    "    \n",
    "    #corner case to check aspect terms are lesser or equal to the text\n",
    "    if set(aspect) <= set(text):\n",
    "        \n",
    "        #to store left and right weights\n",
    "        leftWeights = rightWeights = []\n",
    "        \n",
    "        #find the starting point of the first aspect term word\n",
    "        aspect_start = [i for i, word in enumerate(text) if word == aspect[0]]\n",
    "        \n",
    "        #find the start and end indices of the aspect\n",
    "        for pos in (aspect_start):\n",
    "            if  text[(pos + len(aspect) - 1)] == aspect[-1]:\n",
    "                start_index = pos\n",
    "                end_index = pos + len(aspect) - 1\n",
    "                break\n",
    "                \n",
    "        #assign weights to each word moving left and right of the aspect term         \n",
    "        if (end_index - start_index) == len(aspect) - 1:\n",
    "            #get the left side and the right side of the text from the aspect\n",
    "            left_text = text[:start_index]\n",
    "            right_text = text[end_index+1:]\n",
    "            \n",
    "            #generate left and right weights based on a well known strategy\n",
    "            leftWeights = [1/i for i in range(len(left_text),0,-1) if len(left_text) != 0]\n",
    "            rightWeights = [1/i for i in range(1,len(right_text)+1) if len(right_text) != 0]\n",
    "         \n",
    "        #find the total weights by adding a constant\n",
    "        tot_weights = leftWeights + [2]*len(aspect) + rightWeights\n",
    "        \n",
    "        #return the dict of text and its weights\n",
    "        return dict(zip(text,tot_weights))\n",
    "    else: \n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_aspect_term</th>\n",
       "      <th>element_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2333_1</td>\n",
       "      <td>Obviously one of the most important features o...</td>\n",
       "      <td>human interface</td>\n",
       "      <td>69--84</td>\n",
       "      <td>0</td>\n",
       "      <td>[Obviously, one, important, feature, computer,...</td>\n",
       "      <td>[human, interface]</td>\n",
       "      <td>{'Obviously': 0.2, 'one': 0.25, 'important': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1805_1</td>\n",
       "      <td>Good for every day computing and web browsing.</td>\n",
       "      <td>every day computing</td>\n",
       "      <td>9--28</td>\n",
       "      <td>1</td>\n",
       "      <td>[Good, every, day, computing, web, browsing]</td>\n",
       "      <td>[every, day, computing]</td>\n",
       "      <td>{'Good': 1.0, 'every': 2, 'day': 2, 'computing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2782_2</td>\n",
       "      <td>while the keyboard itself is alright[comma] th...</td>\n",
       "      <td>mouse command buttons</td>\n",
       "      <td>115--136</td>\n",
       "      <td>-1</td>\n",
       "      <td>[keyboard, alright, plate, around, cheap, plas...</td>\n",
       "      <td>[mouse, command, button]</td>\n",
       "      <td>{'keyboard': 0.1, 'alright': 0.111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1385_0</td>\n",
       "      <td>Again[comma] the same problem[comma] the right...</td>\n",
       "      <td>right speaker</td>\n",
       "      <td>29--42</td>\n",
       "      <td>-1</td>\n",
       "      <td>[Again, problem, right, speaker, work]</td>\n",
       "      <td>[right, speaker]</td>\n",
       "      <td>{'Again': 0.5, 'problem': 1.0, 'right': 2, 'sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1423_0</td>\n",
       "      <td>My problem was with DELL Customer Service.</td>\n",
       "      <td>DELL Customer Service</td>\n",
       "      <td>20--41</td>\n",
       "      <td>-1</td>\n",
       "      <td>[My, problem, DELL, Customer, Service]</td>\n",
       "      <td>[DELL, Customer, Service]</td>\n",
       "      <td>{'My': 0.5, 'problem': 1.0, 'DELL': 2, 'Custom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text  \\\n",
       "0     2333_1  Obviously one of the most important features o...   \n",
       "1     1805_1     Good for every day computing and web browsing.   \n",
       "2     2782_2  while the keyboard itself is alright[comma] th...   \n",
       "3     1385_0  Again[comma] the same problem[comma] the right...   \n",
       "4     1423_0         My problem was with DELL Customer Service.   \n",
       "\n",
       "             aspect_term term_location  class  \\\n",
       "0        human interface        69--84      0   \n",
       "1    every day computing         9--28      1   \n",
       "2  mouse command buttons      115--136     -1   \n",
       "3          right speaker        29--42     -1   \n",
       "4  DELL Customer Service        20--41     -1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  [Obviously, one, important, feature, computer,...   \n",
       "1       [Good, every, day, computing, web, browsing]   \n",
       "2  [keyboard, alright, plate, around, cheap, plas...   \n",
       "3             [Again, problem, right, speaker, work]   \n",
       "4             [My, problem, DELL, Customer, Service]   \n",
       "\n",
       "           clean_aspect_term  \\\n",
       "0         [human, interface]   \n",
       "1    [every, day, computing]   \n",
       "2   [mouse, command, button]   \n",
       "3           [right, speaker]   \n",
       "4  [DELL, Customer, Service]   \n",
       "\n",
       "                                     element_weights  \n",
       "0  {'Obviously': 0.2, 'one': 0.25, 'important': 0...  \n",
       "1  {'Good': 1.0, 'every': 2, 'day': 2, 'computing...  \n",
       "2  {'keyboard': 0.1, 'alright': 0.111111111111111...  \n",
       "3  {'Again': 0.5, 'problem': 1.0, 'right': 2, 'sp...  \n",
       "4  {'My': 0.5, 'problem': 1.0, 'DELL': 2, 'Custom...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign weights to the data\n",
    "df1['element_weights'] = df1[['clean_text','clean_aspect_term']].apply(assign_weights, axis = 1)\n",
    "\n",
    "#drop all nan values\n",
    "df1 = df1.dropna()\n",
    "\n",
    "#create an empty df with zeros\n",
    "df2 = pd.DataFrame(np.zeros((len(df1),len(vocab))),columns=vocab)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the calculated weights to the corresponding text elements of df2\n",
    "for row in range(len(df1)):\n",
    "    for key,value in df1.iloc[row]['element_weights'].items():\n",
    "        df2.iloc[row][key] = value\n",
    "        \n",
    "#feature extraction - transform a count matrix to a normalized tf-idf representation\n",
    "tfidf= TfidfTransformer().fit_transform(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033166742389823"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=1.2)\n",
    "pred_SVM = cross_val_predict(svm,tfidf,df1['class'],cv = 10)\n",
    "\n",
    "np.mean(pred_SVM == df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.2, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(tfidf, df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.68120805, 0.55555556, 0.78251599]), array([0.73639661, 0.47018349, 0.78251599]), array([0.70772807, 0.50931677, 0.78251599]), array([827, 436, 938], dtype=int64))\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.68      0.71       894\n",
      "          0       0.47      0.56      0.51       369\n",
      "          1       0.78      0.78      0.78       938\n",
      "\n",
      "avg / total       0.71      0.70      0.71      2201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(df1['class'], pred_SVM, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred_SVM,df1['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.7, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= processData, ngram_range=(1,5),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec.fit_transform(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df1['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(max_depth=10).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(DT,X,Y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Y==pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_recall_fscore_support(Y, pred, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_NB = MultinomialNB().fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NB= cross_val_predict(clf_NB,X,Y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Y==pred_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_recall_fscore_support(Y, pred_NB, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred_NB,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6566666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RFC = RandomForestClassifier(n_estimators=100,max_depth=200)\n",
    "pred_RF = cross_val_predict(clf_RFC,df2,df1['class'],cv = 10)\n",
    "np.mean(pred_RF == df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.62678063, 0.44015444, 0.67892977]), array([0.27363184, 0.18009479, 0.93851133]), array([0.38095238, 0.25560538, 0.78789055]), array([ 804,  633, 2163], dtype=int64))\n",
      "\n",
      " Classification Report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.63      0.38       351\n",
      "           0       0.18      0.44      0.26       259\n",
      "           1       0.94      0.68      0.79      2990\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      3600\n",
      "   macro avg       0.46      0.58      0.47      3600\n",
      "weighted avg       0.82      0.66      0.71      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(df1['class'], pred_RF, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred_RF,df1['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the columns required\n",
    "testcols=['example_id','text','aspect_term','term_location']\n",
    "df_test = pd.read_csv('./Data-1_test.csv',skipinitialspace=True, usecols=testcols)\n",
    "\n",
    "df_test.columns = ['example_id','text','aspect_term','term_location']\n",
    "countVectorizer = CountVectorizer()\n",
    "count_matrix = countVectorizer.fit_transform(df_test['text'])\n",
    "df_test['text'] = df_test['text'].apply(processData)\n",
    "df_test['processed_AT'] = df_test['aspect_term'].apply(processData)\n",
    "df_test['element_weights'] = df_test[['text','processed_AT']].apply(assign_weights, axis = 1)\n",
    "df_test = df_test.dropna()\n",
    "df2_test = pd.DataFrame(np.zeros((len(df1),len(vocab))),columns=vocab)\n",
    "\n",
    "#assign weights and add it to the dict\n",
    "for row in range(len(df_test)):    \n",
    "    for key,value in df_test.iloc[row]['element_weights'].items():\n",
    "        df2_test.iloc[row][key] = value\n",
    "tfidf= TfidfTransformer().fit_transform(df2_test)\n",
    "\n",
    "#do a single pass over the test data using existing classifier \n",
    "pred_SVM = svm.predict(df2_test)\n",
    "res = list()\n",
    "file = open('KruneetKumar_Patel_Vishwas_SreevalliRamamohan_Data-1.txt','w')\n",
    "\n",
    "#zip example ids with their predictions and write it to a file\n",
    "for x,y in zip(list(df_test['example_id']),pred_SVM):\n",
    "    res.append(str(x) +\";;\"+str(y))\n",
    "for i in res:\n",
    "    file.write(\"%s\\n\"%i)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KruneetKumar_Patel_Vishwas_SreevalliRamamohan_Data-2.txt\n",
    "# KruneetKumar_Patel_Vishwas_SreevalliRamamohan_Data-1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "with open('KruneetKumar_Patel_Vishwas_SreevalliRamamohan_Data-2.txt','r') as f:\n",
    "    x = f.readlines()\n",
    "    for y in x:\n",
    "        i += 1 \n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_SVM==[-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df1.copy()\n",
    "df1['clean_text']= \" \".join(df1['clean_text'])\n",
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.7, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= 'word', ngram_range=(1,5),lowercase=True)\n",
    "X = vec.fit_transform(data['text'])\n",
    "svm = LinearSVC(C=1.2)\n",
    "pred_weights = cross_val_predict(svm,X,data['class'],cv = 10)\n",
    "np.mean(pred_weights == data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sentText'] = [\" \".join(x) for x in df1['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sentAspect'] = [\" \".join(c) for c in df1['clean_aspect_term']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.5, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= 'word', ngram_range=(1,10),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec.fit_transform(df1['sentText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(C=1.2)\n",
    "pred_weights = cross_val_predict(svm, X ,df1['class'],cv = 10)\n",
    "len(pred_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_weights == df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
